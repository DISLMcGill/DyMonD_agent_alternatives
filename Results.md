# Results
DyMonD is a software that dynamically monitors an application and extracts information about the service components. It is composed of two parts: an agent, or ‘sniffer’, and a controller. The controller is implemented in C++, and the agent in python. The agent’s role is to intercept a series of messages between the service components of the application being monitored. These messages are collected, and then passed to a deep learning model, which infers the service type of the component associated with each message. These predictions are then sent back to the controller. Since the deep learning model is implemented in python, a slower language than C++, this process of message interception, service type prediction, and data transfer is inefficient. The aim of this research project was to explore alternative approaches to a python deep learning model, with the goal of improving the efficiency of this process. The methods explored were the Keras2C library, and the Tensorflow C and C++ APIs.

Keras2C is a library that takes a trained deep learning model in python and converts it into C, along with an automatically generated test-suite. The test-suite contains a series of random inputs for the model, held in ‘tensor’ format. During the construction of the test-suite, the original python model is tested with the same random data, and its predictions are stored. When the test-suite is run, the same random inputs are fed to the newly created C model. The C model then runs its inference on the data, and calculates predictions, which are stored in separate tensors. In this case, there are ten possible service types for the models to infer between. Then, the python and C models’ predictions are compared, and the maximum absolute error is calculated and printed to the screen.

On converting DyMonD’s deep learning model to C, the test-suite showed that the maximum absolute error between the C and python models’ predictions was 3.159e-06; the original python and converted C models made almost identical predictions. The automatically generated tests, however, appeared to be flawed. This was established in a separate experiment, in which a python model with two of the ten classes was converted with Keras2C, and the test-suite analyzed. It was found that the test-suite had only generated data that matched the first of the two classes. 

In order to analyze the performance of the converted C model on a legitimate dataset, a new test-suite was generated. Instead of comparing the output of the C model to the output of the python model directly, the C model’s predictions were compared to real values. These results, shown in figure 1, could then be compared to the python model’s predictions on the same data. The predictions from the C model had an f1 score, a recall and a precision of 0.982, and an accuracy of 0.996. The original python model (saved as a .h5 model), had an f1 score, recall and precision of 0.981, and an accuracy of 0.982.  The converted C model improved on the original model’s accuracy. The average individual Keras2C prediction also took approximately half the time as the average python prediction, at 5.43e-03s vs 9.94e-03s. When given a larger batch of inputs, however, the Keras2C was less efficient. With a dataset with 5643 inputs, the average time to format the data and make predictions with a Keras2C test-suite-like script was 29.9s,  whereas the python model took 7.19s. This could be explained by the format of the Keras2C test suite: for each individual input, a new tensor is created and the data is tested with the model in a new session. In the python model, however, the input is fed to the model as a whole: this seems to be a more effective method as the size of the data set increases. Perhaps, since the time for an individual test with a Keras2C model is faster, if the test-suite could be improved to concatenate all inputs into a single tensor, this could be a viable option for improving the efficiency of the DyMonD sniffer. Also, with the sniffer, only small batches of inputs are given at a time. Keras2C could then be an effective solution to pursue (with some extra code to integrate the C model with the C++ controller). 

The next approach explored was the Tensorflow C API, which provides a framework for using a machine learning model to generate predictions in C. Instead of converting a python model to C, this method creates a wrapper for a trained python model. The Tensorflow C API comes with a series of functions that enable the user to construct a program which takes a trained keras model and input data, and outputs predictions in an array-like structure. Whereas in the Keras2C trial, each input formed a separate tensor, here, it was possible to feed all inputs to a single larger tensor. This method was very efficient with larger input batches. With the dataset of 5643 inputs, the entire process took, on average, 0.462s. This is considerably faster than both the Keras2C approach and the python approach. In addition, the predictions were highly accurate, more so than the initial python approach and the Keras2C approach, with an f1 score, accuracy, recall and precision of 0.997. The average time for a single prediction with the C API was 7.01e-3s, slightly faster than the initial python model, and slightly slower than the converted Keras2C model. The model in this method is still a python model, which would explain why it was slightly slower than Keras2C’s converted C model (as C is an inherently faster language). Although the time for an individual prediction was only marginally faster than the initial python model (mentioned above), the C API vastly improved the efficiency of the rest of the process (shaping and normalizing data, building structures to hold inputs and outputs, processing results). It had an advantage over the python model as it was written in a faster language, and it had a structural advantage over the Keras2C test-suite code, as the inputs were processed in a single session. 

In DyMonD, the agent is written in C++, and not in C. Therefore, in order to implement new agent code, the Tensorflow C API process would need to be implemented in C++. The Tensorflow C++ API has a very similar functionality and format to the C API: it also provides a wrapper for a trained python model, saved in a .pb format. In order to use the C++ API, you need to build Tensorflow for C++ from source. Once the C++ API is built, a program which inputs data, processes and outputs predictions in a similar way to the C API can be constructed and potentially could improve the efficiency of the agent code in DyMonD. 

The API can be built in two ways: linked to a project or as a standalone program. When it is built and linked to a project, the project is written first – a script to generate predictions from a model – and then Tensorflow is built from the project’s folder, in reference to the project. As a standalone program, the API is built separately and then linked to the project at compile-time. This method was chosen as it is more flexible, allowing the API to be used in future projects. Building tensorflow from source is a process that takes multiple hours and can be very finicky. Once tensorflow was built, the C++ code to process input data and generate predictions was written. The C++ API script, on average, had a total execution time of 11.5s, over the 5643 tests. This is an improvement over Keras2C, as again, the data was formatted to be processed in a single tensor, and a single session was run, as opposed to multiple tensors and multiple sessions. This execution time, however, was surprisingly slower than the initial python model, which took on average 7.19s. The time per prediction was 6.61e-03s. This is a minor improvement over the original python .h5 model, which took 9.94e-03s. The accuracy of predictions with the Tensorflow C++ API was also very high, with an f1 score of 0.997. This tied the Tensorflow C API as the method that generated the most accurate predictions. Although it was slightly less efficient with larger batch sizes, considering the format of DyMonD software, this method could be a good replacement for the initial python model. This script would also be easier to integrate with the controller, as it is written in C++.

In conclusion, the Tensorflow C and C++ APIs were more effective at handling a larger batch of inputs (especially the C API), and could be pursued as solutions to increase the efficiency of the sniffer. Although the C API was a lot faster with a larger input batch, the C++ API had a faster individual prediction time, and is written in C++. The Tensorflow C++ API seems to be the better solution, given the format of DyMonD, which processes small batches of inputs at a time. Both methods also had higher accuracies than both the initial python model and Keras2C. The Keras2C method, however, had the fastest time for an individual prediction; if the process could be made more efficient, this could be a viable solution as well. 


Figure 1: Results    |  Keras2C   |  Python .h5 Model  | Tensorflow C API   | Tensorflow C++ API
-------------------- | ---------- | ------------------ | ------------------ | ----------------------           
F1 Score             |  0.982     |  0.981             |  0.997             |  0.997
-------------------- |            |                    |                    |  
Accuracy             |  0.996     |  0.982             |  0.999             |  0.999
-------------------- |            |                    |                    |  
Recall               |  0.982     |  0.981             |  0.997             |  0.997
-------------------- |            |                    |                    |  
Precision            |  0.982     |  0.981             |  0.997             |  0.997
-------------------- |            |                    |                    |  
Average time         | 5.43e-03s  |   9.94e-03s        |  7.01e03s          | 6.61e-03s
per test             |            |                    |                    |
(5643 total)         |            |                    |                    |
                     |            |                    |                    |  
Average time         | 29.89s     |  7.19s             |  0.462s            |  11.5s
for process w/5643   |            |                    |                    |
tests (loading data  |            |                    |                    |
->prediction output) |            |                    |                    |




